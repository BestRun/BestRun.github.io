<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>b1ue0cean&#39;s world</title>
    <link>https://BestRun.github.io/</link>
    <description>b1ue0cean&#39;s world</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sat, 21 Oct 2023 17:35:46 +0800</lastBuildDate>
    
    <atom:link href="https://BestRun.github.io/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Research on in Context Few Shot Learning</title>
      <link>https://BestRun.github.io/posts/research-on-in-context-few-shot-learning/</link>
      <pubDate>Sat, 21 Oct 2023 17:35:46 +0800</pubDate>
      
      <guid>https://BestRun.github.io/posts/research-on-in-context-few-shot-learning/</guid>
      <description>&lt;p&gt;OK, this title may be wried, ah&lt;/p&gt;
&lt;p&gt;it mix two concepts,&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;few shot learner&lt;/li&gt;
&lt;li&gt;in context learning&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Here are several paper about this topic, and I will spent some time to reading all of them next week.
Four paper mentioned in the chatafl paper&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Language models are few-shot learners&lt;/li&gt;
&lt;li&gt;How does in-context learning help prompt tuning?&lt;/li&gt;
&lt;li&gt;Self-consistency improves chain of thought reasoning in language models&lt;/li&gt;
&lt;li&gt;Chain of thought prompting elicits reasoning in large language models&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;And some I found,&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Skill-Based Few-Shot Selection for In-Context Learning&lt;/li&gt;
&lt;li&gt;Language Models are Few-Shot Learners&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Language models are few-shot learners is the original paper of GPT3
&lt;a href=&#34;https://sh-tsang.medium.com/review-gpt-3-language-models-are-few-shot-learners-ff3e63da944d&#34;&gt;https://sh-tsang.medium.com/review-gpt-3-language-models-are-few-shot-learners-ff3e63da944d&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Research about the Field of Encrypted Malicious Traffic Detection</title>
      <link>https://BestRun.github.io/posts/encrypted-malicious-traffic-research/</link>
      <pubDate>Sat, 21 Oct 2023 15:04:21 +0800</pubDate>
      
      <guid>https://BestRun.github.io/posts/encrypted-malicious-traffic-research/</guid>
      <description>&lt;h2 id=&#34;research-condition&#34; &gt;Research Condition
&lt;span&gt;
    &lt;a href=&#34;#research-condition&#34;&gt;
        &lt;svg viewBox=&#34;0 0 28 23&#34; height=&#34;100%&#34; width=&#34;19&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34;&gt;&lt;path d=&#34;M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;path d=&#34;M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;/svg&gt;
    &lt;/a&gt;
&lt;/span&gt;
&lt;/h2&gt;&lt;p&gt;Firstly, I&amp;rsquo;d like to spent some time on datasets and related papers.&lt;/p&gt;
&lt;h3 id=&#34;paper&#34; &gt;Paper
&lt;span&gt;
    &lt;a href=&#34;#paper&#34;&gt;
        &lt;svg viewBox=&#34;0 0 28 23&#34; height=&#34;100%&#34; width=&#34;19&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34;&gt;&lt;path d=&#34;M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;path d=&#34;M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;/svg&gt;
    &lt;/a&gt;
&lt;/span&gt;
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;Detecting Unknown Encrypted Malicious Traffic in Real Time via Flow Interaction Graph Analysis&lt;/li&gt;
&lt;li&gt;Realtime Robust Malicious Traffic Detection via Frequency Domain Analysis&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;dataset&#34; &gt;Dataset
&lt;span&gt;
    &lt;a href=&#34;#dataset&#34;&gt;
        &lt;svg viewBox=&#34;0 0 28 23&#34; height=&#34;100%&#34; width=&#34;19&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34;&gt;&lt;path d=&#34;M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;path d=&#34;M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;/svg&gt;
    &lt;/a&gt;
&lt;/span&gt;
&lt;/h3&gt;&lt;p&gt;waiting to write &amp;hellip;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Paper Reading Note - CHATAFL</title>
      <link>https://BestRun.github.io/posts/paper-reading-note-chatafl/</link>
      <pubDate>Sat, 21 Oct 2023 15:03:05 +0800</pubDate>
      
      <guid>https://BestRun.github.io/posts/paper-reading-note-chatafl/</guid>
      <description>&lt;h2 id=&#34;before-reading&#34; &gt;Before Reading
&lt;span&gt;
    &lt;a href=&#34;#before-reading&#34;&gt;
        &lt;svg viewBox=&#34;0 0 28 23&#34; height=&#34;100%&#34; width=&#34;19&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34;&gt;&lt;path d=&#34;M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;path d=&#34;M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;/svg&gt;
    &lt;/a&gt;
&lt;/span&gt;
&lt;/h2&gt;&lt;p&gt;Actually, this work is very similar to my research direction in my internship project. I also think some ideas to use LLM to fuzz, but because my work ability and timeline, I haven&amp;rsquo;t finish my project yet. So, today I will summarize  the good idea contributed from this paper.&lt;/p&gt;
&lt;p&gt;Before diving into it, I have a few questions:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Where and how can LLM be applied to fuzzing?
&lt;ul&gt;
&lt;li&gt;In state transitions?&lt;/li&gt;
&lt;li&gt;In testcase generation?&lt;/li&gt;
&lt;li&gt;In mutation?&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Regarding LLM:
&lt;ul&gt;
&lt;li&gt;Which LLM was used by the author?&lt;/li&gt;
&lt;li&gt;Did the author fine-tune it?&lt;/li&gt;
&lt;li&gt;If so, how was it fine-tuned?&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Which protocol did the author research?&lt;/li&gt;
&lt;li&gt;What are the cost and efficiency considerations?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;With these questions in mind, I will begin my reading.&lt;/p&gt;
&lt;h2 id=&#34;start-reading&#34; &gt;Start Reading
&lt;span&gt;
    &lt;a href=&#34;#start-reading&#34;&gt;
        &lt;svg viewBox=&#34;0 0 28 23&#34; height=&#34;100%&#34; width=&#34;19&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34;&gt;&lt;path d=&#34;M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;path d=&#34;M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;/svg&gt;
    &lt;/a&gt;
&lt;/span&gt;
&lt;/h2&gt;&lt;h3 id=&#34;abstract&#34; &gt;Abstract
&lt;span&gt;
    &lt;a href=&#34;#abstract&#34;&gt;
        &lt;svg viewBox=&#34;0 0 28 23&#34; height=&#34;100%&#34; width=&#34;19&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34;&gt;&lt;path d=&#34;M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;path d=&#34;M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;/svg&gt;
    &lt;/a&gt;
&lt;/span&gt;
&lt;/h3&gt;&lt;blockquote&gt;
&lt;p&gt;Our protocol fuzzer CHATAFL constructs grammars for each message type in a protocol, and then mutates messages or predicts the next messages in a message sequence via interactions with LLMs. |&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;And the CHATAFL improve the coverage compare with NSFUZZ.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;CHATAFL covers 47.60% and 42.69% more state transitions, 29.55% and 25.75% more states, and 5.81% and 6.74% more code, respectively.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;introduction&#34; &gt;INTRODUCTION
&lt;span&gt;
    &lt;a href=&#34;#introduction&#34;&gt;
        &lt;svg viewBox=&#34;0 0 28 23&#34; height=&#34;100%&#34; width=&#34;19&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34;&gt;&lt;path d=&#34;M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;path d=&#34;M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;/svg&gt;
    &lt;/a&gt;
&lt;/span&gt;
&lt;/h3&gt;&lt;p&gt;The concept of &amp;ldquo;LLM-guided protocol fuzzing&amp;rdquo;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;the fuzzer uses the LLM to extract a machine-readable grammar for a protocol that is used for structure-aware mutation&lt;/li&gt;
&lt;li&gt;the fuzzer uses the LLM to increase the diversity of messages in the recorded message sequences that are used as initial seeds.&lt;/li&gt;
&lt;li&gt;the fuzzer uses the LLM to break out of a coverage plateau, where the LLM is prompted to generate messages to reach new states.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Than the author compare the efficiency of chatafl with &lt;a href=&#34;https://github.com/profuzzbench/profuzzbench&#34;&gt;protocol fuzzer benchmark&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id=&#34;background-and-motivation&#34; &gt;BACKGROUND AND MOTIVATION
&lt;span&gt;
    &lt;a href=&#34;#background-and-motivation&#34;&gt;
        &lt;svg viewBox=&#34;0 0 28 23&#34; height=&#34;100%&#34; width=&#34;19&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34;&gt;&lt;path d=&#34;M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;path d=&#34;M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;/svg&gt;
    &lt;/a&gt;
&lt;/span&gt;
&lt;/h3&gt;&lt;p&gt;Here, the author suggest some challenges&lt;/p&gt;
&lt;blockquote&gt;
&lt;ol&gt;
&lt;li&gt;(C1) Dependence on initial seeds. The effectiveness of mutation-based protocol fuzzers is severely limited by the provided initial seed inputs. The pre-recorded message sequences will hardly cover the great diversity of protocol states and input structures as discussed in the protocol specification.&lt;/li&gt;
&lt;li&gt;(C2) Unknown message structure. Without machinereadable information about the message structure, the fuzzer cannot make structurally interesting changes to the seed messages, e.g., to construct messages of unseen types or to remove, substitute, or add an entire, coherent data structure to a seed message.&lt;/li&gt;
&lt;li&gt;(C3) Unknown state space. Without machinereadable information about the state space, the fuzzer cannot identify the current state or be directed to explore previously unseen states.&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;
&lt;p&gt;Actually, what&amp;rsquo;s most appealing here is the solution for the &amp;ldquo;state,&amp;rdquo; the rest is just so so. Regarding the &amp;ldquo;state,&amp;rdquo; I need to find out which specific state the author is referring to later.&lt;/p&gt;
&lt;p&gt;There are three state in Fuzzing&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://BestRun.github.io/pictures/20231021161745.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;Next, let&amp;rsquo;s see the Motivation, here the author introduce their solutions for the three challenges mentioned above.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Addressing seed dependence by having the LLM &lt;strong&gt;add a random message&lt;/strong&gt; to a seed message sequence, with a focus on improving message diversity and validity (C1).&lt;/li&gt;
&lt;li&gt;Dealing with unknown message structures by &lt;strong&gt;requesting the LLM to provide machine-readable information&lt;/strong&gt; about message grammar for various message types, with a focus on assessing the quality and coverage of these grammars compared to the ground truth (C2).&lt;/li&gt;
&lt;li&gt;Navigating the unknown state space by &lt;strong&gt;requesting the LLM to generate a message that leads to a new state&lt;/strong&gt;, with an investigation into the effectiveness of this approach (C3).&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;How to tell LLM to generate, wondering to know!&lt;/p&gt;
&lt;h3 id=&#34;case-study-testing-the-capabilities-of-llms-for-protocol-fuzzing&#34; &gt;CASE STUDY: TESTING THE CAPABILITIES OF LLMS FOR PROTOCOL FUZZING
&lt;span&gt;
    &lt;a href=&#34;#case-study-testing-the-capabilities-of-llms-for-protocol-fuzzing&#34;&gt;
        &lt;svg viewBox=&#34;0 0 28 23&#34; height=&#34;100%&#34; width=&#34;19&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34;&gt;&lt;path d=&#34;M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;path d=&#34;M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;/svg&gt;
    &lt;/a&gt;
&lt;/span&gt;
&lt;/h3&gt;&lt;p&gt;Skip to the third part: Inducing Interesting State Transitions&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;We provide the LLM the message exchange between fuzzer and the protocol implementation and ask it to return a message that would lead to a new state. We evaluate how likely the message induce a transition to a new state. Specifically, we provide the LLM with existing communication history, enabling a server respectively to reach each state (i.e., INIT, READY, PLAY, and RECORD). Afterward, we query the LLM to determine the next client requests that can affect the server’s state. To mitigate the influence of the LLM’s stochastic behavior, we prompted the LLM 100 times for each state.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Actually, I had proposed the same idea before, but I hadn&amp;rsquo;t put it into practice because we selected a more complex target. Perhaps this event is educational for me. I should do some practices from the simplest target.&lt;/p&gt;
&lt;p&gt;Perhaps considering how to minimize the LLM cost in algorithm design could also be a promising research direction?&lt;/p&gt;
&lt;h3 id=&#34;llm-guided-protocol-fuzzing&#34; &gt;LLM-GUIDED PROTOCOL FUZZING
&lt;span&gt;
    &lt;a href=&#34;#llm-guided-protocol-fuzzing&#34;&gt;
        &lt;svg viewBox=&#34;0 0 28 23&#34; height=&#34;100%&#34; width=&#34;19&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34;&gt;&lt;path d=&#34;M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;path d=&#34;M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;/svg&gt;
    &lt;/a&gt;
&lt;/span&gt;
&lt;/h3&gt;&lt;h4 id=&#34;a-grammar-guided-mutation&#34; &gt;A. Grammar-guided Mutation
&lt;span&gt;
    &lt;a href=&#34;#a-grammar-guided-mutation&#34;&gt;
        &lt;svg viewBox=&#34;0 0 28 23&#34; height=&#34;100%&#34; width=&#34;19&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34;&gt;&lt;path d=&#34;M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;path d=&#34;M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;/svg&gt;
    &lt;/a&gt;
&lt;/span&gt;
&lt;/h4&gt;&lt;h5 id=&#34;1-grammar-extraction&#34; &gt;1) Grammar Extraction
&lt;span&gt;
    &lt;a href=&#34;#1-grammar-extraction&#34;&gt;
        &lt;svg viewBox=&#34;0 0 28 23&#34; height=&#34;100%&#34; width=&#34;19&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34;&gt;&lt;path d=&#34;M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;path d=&#34;M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;/svg&gt;
    &lt;/a&gt;
&lt;/span&gt;
&lt;/h5&gt;&lt;p&gt;Here, the author use a method to generate message grammar called &amp;ndash; in-context few-shot learning. Cool, this is a super idea!&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;In-context learning serves as an effective approach to fine-tuning the model. Few-shot learning is utilized to enhance the context with a few examples of desired inputs and outputs. This enables the LLM to recognize the input prompt syntax and output patterns.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h5 id=&#34;2-mutation-based-on-grammar&#34; &gt;2) Mutation based on Grammar
&lt;span&gt;
    &lt;a href=&#34;#2-mutation-based-on-grammar&#34;&gt;
        &lt;svg viewBox=&#34;0 0 28 23&#34; height=&#34;100%&#34; width=&#34;19&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34;&gt;&lt;path d=&#34;M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;path d=&#34;M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;/svg&gt;
    &lt;/a&gt;
&lt;/span&gt;
&lt;/h5&gt;&lt;p&gt;skip!&lt;/p&gt;
&lt;h4 id=&#34;b-enriching-initial-seeds&#34; &gt;B. Enriching Initial Seeds
&lt;span&gt;
    &lt;a href=&#34;#b-enriching-initial-seeds&#34;&gt;
        &lt;svg viewBox=&#34;0 0 28 23&#34; height=&#34;100%&#34; width=&#34;19&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34;&gt;&lt;path d=&#34;M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;path d=&#34;M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;/svg&gt;
    &lt;/a&gt;
&lt;/span&gt;
&lt;/h4&gt;&lt;p&gt;skip!&lt;/p&gt;
&lt;h4 id=&#34;c-surpassing-coverage-plateau&#34; &gt;C. Surpassing Coverage Plateau
&lt;span&gt;
    &lt;a href=&#34;#c-surpassing-coverage-plateau&#34;&gt;
        &lt;svg viewBox=&#34;0 0 28 23&#34; height=&#34;100%&#34; width=&#34;19&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34;&gt;&lt;path d=&#34;M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;path d=&#34;M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;/svg&gt;
    &lt;/a&gt;
&lt;/span&gt;
&lt;/h4&gt;&lt;p&gt;A complex design, let&amp;rsquo;s skip it! For have my own ideas, but they&amp;rsquo;re not suitable to share.&lt;/p&gt;
&lt;img src=&#34;https://BestRun.github.io/pictures/20231021170616.png&#34; width=&#34;600&#34; height=&#34;1200&#34;&gt;</description>
    </item>
    
    <item>
      <title>A diary in a special time</title>
      <link>https://BestRun.github.io/posts/a-simple-diary/</link>
      <pubDate>Sat, 21 Oct 2023 11:15:13 +0800</pubDate>
      
      <guid>https://BestRun.github.io/posts/a-simple-diary/</guid>
      <description>&lt;h2 id=&#34;my-life-and-mental-state&#34; &gt;My life and mental state
&lt;span&gt;
    &lt;a href=&#34;#my-life-and-mental-state&#34;&gt;
        &lt;svg viewBox=&#34;0 0 28 23&#34; height=&#34;100%&#34; width=&#34;19&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34;&gt;&lt;path d=&#34;M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;path d=&#34;M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;/svg&gt;
    &lt;/a&gt;
&lt;/span&gt;
&lt;/h2&gt;&lt;p&gt;Today is Saturday, and I don&amp;rsquo;t want to overwhelm myself with work, even though I&amp;rsquo;m facing the most intense pressure I&amp;rsquo;ve ever experienced in my undergraduate years as I strive to secure a Master&amp;rsquo;s or PhD position.&lt;/p&gt;
&lt;p&gt;Just yesterday, I gave a presentation for one of my courses. The teacher, an associate professor from Canada, transformed the presentation into a meaningful conversation. He offered a piece of advice that has left a lasting impact on me and provided valuable lessons. He emphasized the importance of always being prepared for a presentation and understanding the purpose at any given time. This advice is especially crucial when you&amp;rsquo;re planning to study abroad, as it&amp;rsquo;s easy to feel lost in a new environment. He humorously added, &amp;ldquo;In many years, you might forget my name and the name of the course, but you&amp;rsquo;ll remember being in a strange place, with an strange course and teacher, telling you to always be prepared and know your purpose.&amp;rdquo;&lt;/p&gt;
&lt;p&gt;His words deeply resonated with me. Lately, I&amp;rsquo;ve been juggling various commitments, such as internships, preparing for the IELTS, and applying for Master&amp;rsquo;s programs. It&amp;rsquo;s been three months since I last wrote a blog or reflected on my life and studies.So today, I took a moment to sit down in my lab and write this blog to summarize the past few months of my work and life.&lt;/p&gt;
&lt;p&gt;I&amp;rsquo;d like to share what I&amp;rsquo;ve been up to recently. Firstly, I&amp;rsquo;m still engrossed in my internship project focused on fuzzing at ISCAS. What&amp;rsquo;s more, I&amp;rsquo;m about to commence work with Professor Xing on the AIxCC competition, and I&amp;rsquo;m faced with three course projects that I must complete – it feels like quite a workload!&lt;/p&gt;
&lt;p&gt;Additionally, this week I&amp;rsquo;ve prepared all the application materials for my UK university applications. I&amp;rsquo;m set to apply to the University of Southampton next Monday.&lt;/p&gt;
&lt;p&gt;Furthermore, I&amp;rsquo;m in the process of deciding the direction for my bachelor&amp;rsquo;s thesis. I can use the progress I made in AIxCC competition as my bachelor&amp;rsquo;s thesis, but my school tutor also give my a direction about detecting encrypted malicious traffic.&lt;/p&gt;
&lt;p&gt;On top of all this, my IELTS score currently stands at only 6. I need to put in the effort to improve it to 6.5 by the end of this year. And, I also have to obtain a GRE score this year! The NUS need GRE grade, cry!&lt;/p&gt;
&lt;p&gt;Yes, there are just too many tasks on my plate.&lt;/p&gt;
&lt;p&gt;Despite my initial intention to avoid discussing anything related to computer knowledge formally, I&amp;rsquo;ve found it difficult to do so. First, let me list all the tasks I need to complete:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Course projects
&lt;ul&gt;
&lt;li&gt;NLP course&lt;/li&gt;
&lt;li&gt;CV course&lt;/li&gt;
&lt;li&gt;AI Reach Practice&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Internship project&lt;/li&gt;
&lt;li&gt;IELTS&lt;/li&gt;
&lt;li&gt;GRE&lt;/li&gt;
&lt;li&gt;AIxCC competition&lt;/li&gt;
&lt;li&gt;School applications (Personal Statement, Reference Letter, and so on&amp;hellip;)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;However, I want to make it clear that I&amp;rsquo;m not writing this blog to complain. My aim is to tackle these challenges one by one.&lt;/p&gt;
&lt;h2 id=&#34;some-research-experiences&#34; &gt;Some Research experiences
&lt;span&gt;
    &lt;a href=&#34;#some-research-experiences&#34;&gt;
        &lt;svg viewBox=&#34;0 0 28 23&#34; height=&#34;100%&#34; width=&#34;19&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34;&gt;&lt;path d=&#34;M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;path d=&#34;M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;/svg&gt;
    &lt;/a&gt;
&lt;/span&gt;
&lt;/h2&gt;&lt;p&gt;After that, I want to share some research experiences I&amp;rsquo;ve faced in the last few months. Perhaps I should list them for a clearer expression.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;You should divide your tasks into smaller, more manageable ones until you can.&lt;/li&gt;
&lt;li&gt;Many times, you may think you&amp;rsquo;ve found a paper that could solve your problems, but most of the time, you&amp;rsquo;ll find it couldn&amp;rsquo;t after some experimentation. This is a common occurrence, so keep on reading and trying.&lt;/li&gt;
&lt;li&gt;Writing a weekly summary, in my internship, it is called a &amp;ldquo;weekly report,&amp;rdquo; can make your project clearer, and perhaps you will get new ideas when you write it.&lt;/li&gt;
&lt;li&gt;Don&amp;rsquo;t always think you should wait until you are well-prepared to start. When you&amp;rsquo;re confused, what you should do is start. You can do five or more tasks, even if they are not well-prepared, instead of one task for which you&amp;rsquo;ve prepared everything well.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Hope everything goes smoothly afterwards!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>about &amp; CV</title>
      <link>https://BestRun.github.io/about/about/</link>
      <pubDate>Tue, 29 Aug 2023 18:37:28 +0800</pubDate>
      
      <guid>https://BestRun.github.io/about/about/</guid>
      <description>&lt;h2 id=&#34;whoami&#34; &gt;WHOAMI
&lt;span&gt;
    &lt;a href=&#34;#whoami&#34;&gt;
        &lt;svg viewBox=&#34;0 0 28 23&#34; height=&#34;100%&#34; width=&#34;19&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34;&gt;&lt;path d=&#34;M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;path d=&#34;M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;/svg&gt;
    &lt;/a&gt;
&lt;/span&gt;
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;FZU, a 211 university in Southeast China&lt;/li&gt;
&lt;li&gt;a baby AI researcher and a CTF player&lt;/li&gt;
&lt;li&gt;current CTF team: r3kapig&lt;/li&gt;
&lt;li&gt;Lab: Key Laboratory of Network Computing and Intelligent Information Processing of Fujian Province&lt;/li&gt;
&lt;li&gt;Research interests: FUZZ / WebSec&lt;/li&gt;
&lt;li&gt;Current status: Internship at ISCAS&lt;/li&gt;
&lt;li&gt;Looking for a phd or master&amp;rsquo;s position in the field of cybersecurity&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;internship-experiences&#34; &gt;Internship experiences
&lt;span&gt;
    &lt;a href=&#34;#internship-experiences&#34;&gt;
        &lt;svg viewBox=&#34;0 0 28 23&#34; height=&#34;100%&#34; width=&#34;19&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34;&gt;&lt;path d=&#34;M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;path d=&#34;M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;/svg&gt;
    &lt;/a&gt;
&lt;/span&gt;
&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;Yigeyun (Jan 2023 - Mar 2023)&lt;/li&gt;
&lt;li&gt;ISCAS (Jul 2023 - )&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;research-experiences&#34; &gt;Research experiences:
&lt;span&gt;
    &lt;a href=&#34;#research-experiences&#34;&gt;
        &lt;svg viewBox=&#34;0 0 28 23&#34; height=&#34;100%&#34; width=&#34;19&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34;&gt;&lt;path d=&#34;M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;path d=&#34;M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;/svg&gt;
    &lt;/a&gt;
&lt;/span&gt;
&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://www.sciencedirect.com/science/article/pii/S1084804523001650&#34;&gt;Capturing spatial–temporal correlations with Attention based Graph Convolutional Network for network traffic prediction&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://ieeexplore.ieee.org/document/10148029&#34;&gt;Network Traffic Prediction with Attention-based Spatial-Temporal Graph Network&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;ctf-competition-experiences&#34; &gt;CTF competition experiences:
&lt;span&gt;
    &lt;a href=&#34;#ctf-competition-experiences&#34;&gt;
        &lt;svg viewBox=&#34;0 0 28 23&#34; height=&#34;100%&#34; width=&#34;19&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34;&gt;&lt;path d=&#34;M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;path d=&#34;M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;/svg&gt;
    &lt;/a&gt;
&lt;/span&gt;
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;Participated in competitions with ROIS during the first and second years.&lt;/li&gt;
&lt;li&gt;Subsequently, joined r3kapig for competitions in 2022. However, limited participation in 2023 due to ongoing application procedures; expecting more time availability after the current semester.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;personal-skills&#34; &gt;Personal skills:
&lt;span&gt;
    &lt;a href=&#34;#personal-skills&#34;&gt;
        &lt;svg viewBox=&#34;0 0 28 23&#34; height=&#34;100%&#34; width=&#34;19&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34;&gt;&lt;path d=&#34;M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;path d=&#34;M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;/svg&gt;
    &lt;/a&gt;
&lt;/span&gt;
&lt;/h2&gt;&lt;p&gt;Skills can be broadly categorized into two areas: machine learning and security.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Machine learning basics including SVM, clustering, etc.&lt;/li&gt;
&lt;li&gt;Familiarity with time series analysis, RNN, and related concepts.&lt;/li&gt;
&lt;li&gt;Some knowledge of Graph Neural Networks (GNN), GCN, GAT, etc.&lt;/li&gt;
&lt;li&gt;Foundational understanding of NLP techniques, including BERT.&lt;/li&gt;
&lt;li&gt;Proficient in using PyTorch and TensorFlow.&lt;/li&gt;
&lt;li&gt;Skilled in code auditing for JAVA and PHP.&lt;/li&gt;
&lt;li&gt;Basic familiarity with node.js and C++.&lt;/li&gt;
&lt;li&gt;A modest understanding of CodeQL.&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Blog Intro</title>
      <link>https://BestRun.github.io/posts/introduction/</link>
      <pubDate>Tue, 29 Aug 2023 18:37:28 +0800</pubDate>
      
      <guid>https://BestRun.github.io/posts/introduction/</guid>
      <description>&lt;h2 id=&#34;hello-everyone&#34; &gt;Hello, everyone!
&lt;span&gt;
    &lt;a href=&#34;#hello-everyone&#34;&gt;
        &lt;svg viewBox=&#34;0 0 28 23&#34; height=&#34;100%&#34; width=&#34;19&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34;&gt;&lt;path d=&#34;M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;path d=&#34;M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;/svg&gt;
    &lt;/a&gt;
&lt;/span&gt;
&lt;/h2&gt;&lt;p&gt;This website is the blog site launched from my secondary GitHub account. Its primary purpose is to migrate Chinese articles after transforming them into English versions. You can visit my original blog at: &lt;a href=&#34;https://b1ue0ceanrun.github.io/&#34;&gt;https://b1ue0ceanrun.github.io/&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
